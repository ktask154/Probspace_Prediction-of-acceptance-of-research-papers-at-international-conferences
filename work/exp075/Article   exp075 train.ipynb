{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3031,"status":"ok","timestamp":1683376079376,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"sMVmfQcW79nK","outputId":"1a8a9a4b-054f-424e-db6c-43142b20fd76"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12781,"status":"ok","timestamp":1683376092146,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"PMsVsVYs8Jib","outputId":"32e0a7f9-7bc1-4504-a453-102981519648"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.12.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683376092147,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"qonwoL_F8Oe_","outputId":"9067695f-b3e4-4629-f639-5d49ecede5e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Sat May  6 12:28:11 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P0    39W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"y2tBjTH68Qnb","executionInfo":{"status":"ok","timestamp":1683376096649,"user_tz":-540,"elapsed":4514,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JyQ97ca88dRA","executionInfo":{"status":"ok","timestamp":1683376096650,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","OUTPUT_EXP_DIR = DIR + '/output/EXP075/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VCF2-czO8Svr","executionInfo":{"status":"ok","timestamp":1683376096650,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model_name=\"sshleifer/distilbart-cnn-12-6\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    model = \"sshleifer/distilbart-cnn-12-6\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=5\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","    num_reinit_layers = 1\n","    is_reinit_layer = False\n","    fgm = False\n","    awp_start=1\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7QkA50jQ80_3","executionInfo":{"status":"ok","timestamp":1683376096650,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return accuracy_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    print(f\"thresh : {best_thresh}\")\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"wRnSUEJR9A9y","executionInfo":{"status":"ok","timestamp":1683376096651,"user_tz":-540,"elapsed":18,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":572,"status":"ok","timestamp":1683376097205,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"GUnukiIG9FM5","outputId":"1b8dbc3a-e47c-43db-c8a9-88fe2a05c7fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 7)\n"]},{"output_type":"display_data","data":{"text/plain":["   index    id                                              title  year  \\\n","0    721   722  Global Optimality Conditions for Deep Neural N...  2018   \n","1    144   145  Multi-Task Learning by Deep Collaboration and ...  2018   \n","2   4542  4543  On the Need for Topology-Aware Generative Mode...  2020   \n","\n","                                            abstract  \\\n","0  We study the error landscape of deep linear an...   \n","1  Convolutional neural networks (CNN) have becom...   \n","2  ML algorithms or models, especially deep neura...   \n","\n","                                            keywords  y  \n","0  deep linear neural networks, global optimality...  1  \n","1  multi-task learning, soft parameter sharing, f...  0  \n","2  Manifold-based Defense, Robust Learning, Adver...  1  "],"text/html":["\n","  <div id=\"df-f80960be-299e-420a-8db8-85c1c4968673\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>721</td>\n","      <td>722</td>\n","      <td>Global Optimality Conditions for Deep Neural N...</td>\n","      <td>2018</td>\n","      <td>We study the error landscape of deep linear an...</td>\n","      <td>deep linear neural networks, global optimality...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>144</td>\n","      <td>145</td>\n","      <td>Multi-Task Learning by Deep Collaboration and ...</td>\n","      <td>2018</td>\n","      <td>Convolutional neural networks (CNN) have becom...</td>\n","      <td>multi-task learning, soft parameter sharing, f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4542</td>\n","      <td>4543</td>\n","      <td>On the Need for Topology-Aware Generative Mode...</td>\n","      <td>2020</td>\n","      <td>ML algorithms or models, especially deep neura...</td>\n","      <td>Manifold-based Defense, Robust Learning, Adver...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f80960be-299e-420a-8db8-85c1c4968673')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f80960be-299e-420a-8db8-85c1c4968673 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f80960be-299e-420a-8db8-85c1c4968673');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-a2507b5f-478e-47e2-9a4b-55edb23c75bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2507b5f-478e-47e2-9a4b-55edb23c75bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a2507b5f-478e-47e2-9a4b-55edb23c75bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a2507b5f-478e-47e2-9a4b-55edb23c75bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-4f4fb3db-f885-4d02-9271-8f0e89ec1288\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f4fb3db-f885-4d02-9271-8f0e89ec1288')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4f4fb3db-f885-4d02-9271-8f0e89ec1288 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4f4fb3db-f885-4d02-9271-8f0e89ec1288');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","train = train.sample(frac=1, random_state=CFG.seed).reset_index()\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"S2LAKUbZ9L92","executionInfo":{"status":"ok","timestamp":1683376097205,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["train[\"texts\"] = train[\"title\"] + \"</s>\" + train[\"abstract\"] "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"9MRHQQ6K9Zot","executionInfo":{"status":"ok","timestamp":1683376097205,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kTf6lgW19iep","executionInfo":{"status":"ok","timestamp":1683376097206,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3931,"status":"ok","timestamp":1683376101133,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wt2P1uC_9oRd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1539f4f0-ca04-458c-d7cb-47f9a3cdcc53"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1524.75it/s]\n","max_len: 653\n","INFO:__main__:max_len: 653\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 3 # cls + sep + sep\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","source":["class AWP:\n","    def __init__(self, model, optimizer, *, adv_param='weight',\n","                 adv_lr=0.001, adv_eps=0.001):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.backup = {}\n","\n","    def perturb(self, inputs, y, criterion):\n","        \"\"\"\n","        Perturb model parameters for AWP gradient\n","        Call before loss and loss.backward()\n","        \"\"\"\n","        self._save()  # save model parameters\n","        self._attack_step()  # perturb weights\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                grad = self.optimizer.state[param]['exp_avg']\n","                norm_grad = torch.norm(grad)\n","                norm_data = torch.norm(param.detach())\n","\n","                if norm_grad != 0 and not torch.isnan(norm_grad):\n","                    # Set lower and upper limit in change\n","                    limit_eps = self.adv_eps * param.detach().abs()\n","                    param_min = param.data - limit_eps\n","                    param_max = param.data + limit_eps\n","\n","                    # Perturb along gradient\n","                    # w += (adv_lr * |w| / |grad|) * grad\n","                    param.data.add_(grad, alpha=(self.adv_lr * (norm_data + e) / (norm_grad + e)))\n","\n","                    # Apply the limit to the change\n","                    param.data.clamp_(param_min, param_max)\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.clone().detach()\n","                else:\n","                    self.backup[name].copy_(param.data)\n","\n","    def restore(self):\n","        \"\"\"\n","        Restore model parameter to correct position; AWP do not perturbe weights, it perturb gradients\n","        Call after loss.backward(), before optimizer.step()\n","        \"\"\"\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data.copy_(self.backup[name])"],"metadata":{"id":"GGPvvwObFq6u","executionInfo":{"status":"ok","timestamp":1683376101134,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rmsbpfsc92bq","executionInfo":{"status":"ok","timestamp":1683376101134,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","source":["def reinit_layers(model):\n","\n","    #for layer in model.model.encoder.layer[-CFG.num_reinit_layers:]:\n","    for layer in model.encoder.layer[-CFG.num_reinit_layers:]:    #Custome model内(backbone)\n","\n","            for module in layer.modules():\n","\n","                if isinstance(module,nn.Linear):\n","                    module.weight.data.normal_(mean=0.0,std=model.config.initializer_range)\n","                    if module.bias is not None:\n","                            module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                        module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                        if module.padding_idx is not None:\n","                            module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                        module.bias.data.zero_()\n","                        module.weight.data.fill_(1.0)\n","                        \n","    return model"],"metadata":{"id":"7_1lWWHZ83or","executionInfo":{"status":"ok","timestamp":1683376101134,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"DbE2YLRd9-uk","executionInfo":{"status":"ok","timestamp":1683376101134,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if CFG.is_reinit_layer:\n","            self.model = reinit_layers(self.model)\n","            print(f'Reinitializing Last {CFG.num_reinit_layers} Layers.')\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MaxPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        #self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        return output"]},{"cell_type":"code","source":["def calculate_loss(inputs, labels, model, criterion, is_valid=True, device=\"cpu\"):    \n","    y_preds = model(inputs)\n","    loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","    return (loss, y_preds) if is_valid else loss"],"metadata":{"id":"ON_p7meJH_tB","executionInfo":{"status":"ok","timestamp":1683376101134,"user_tz":-540,"elapsed":16,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Evhi1yCQ-Xjb","executionInfo":{"status":"ok","timestamp":1683376101135,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, awp):\n","    model.zero_grad()\n","    model.train()\n","    awp_start = CFG.awp_start\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        if epoch >= awp_start:\n","            awp.perturb(inputs, labels, criterion)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            loss = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=False, device=device)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        #loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        if scaler is not None:\n","            scaler.unscale_(optimizer)\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        awp.restore()\n","        if CFG.fgm:\n","          fgm.attack() \n","          adversarial_loss = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=False, device=device)\n","          scaler.scale(adversarial_loss).backward()\n","          fgm.restore()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  #'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          #grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            loss, y_preds = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=True, device=device)\n","        #loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"pR91ZhBL_pW4","executionInfo":{"status":"ok","timestamp":1683376101135,"user_tz":-540,"elapsed":17,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr=5e-6, decoder_lr=1e-4, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \n","                    \"LayerNorm.weight\"]\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n","        group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n","        group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n","        optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    print('Enable AWP')\n","    awp = AWP(model, optimizer, adv_lr=0.001, adv_eps=0.001)\n","    #print('Enable FGM')\n","    #fgm = FGM(model=model, eps=0.1)\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, awp)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score_05 = get_score(valid_labels, predictions)\n","        score = get_acc_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZY5kSe1_1Fl","outputId":"d691ff7a-a9d9-4cad-c558-a6a55c6bb5b8"},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 4s (remain 18m 59s) Loss: 0.5489(0.5489) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 23s (remain 0m 41s) Loss: 0.7158(0.6330) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 42s (remain 0m 16s) Loss: 0.5049(0.6189) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 57s (remain 0m 0s) Loss: 0.5115(0.6104) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5955(0.5955) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6104  avg_val_loss: 0.5961  time: 65s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6104  avg_val_loss: 0.5961  time: 65s\n","Epoch 1 - Score: 0.7068\n","INFO:__main__:Epoch 1 - Score: 0.7068\n","Epoch 1 - Save Best Score: 0.7068 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7068 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6683(0.5961) \n","f1 score : 0.06289308176100629\n","recall score : 0.032679738562091505\n","precision score : 0.8333333333333334\n","thresh : 0.34\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 52s) Loss: 0.5854(0.5854) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.8329(0.5704) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.6840(0.5658) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5245(0.5666) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5465(0.5465) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5666  avg_val_loss: 0.5876  time: 61s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5666  avg_val_loss: 0.5876  time: 61s\n","Epoch 2 - Score: 0.7068\n","INFO:__main__:Epoch 2 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6566(0.5876) \n","f1 score : 0.0617283950617284\n","recall score : 0.032679738562091505\n","precision score : 0.5555555555555556\n","thresh : 0.42\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.4884(0.4884) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 33s) Loss: 0.3303(0.4727) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 37s (remain 0m 14s) Loss: 0.4075(0.4588) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4054(0.4604) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4604(0.4604) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4604  avg_val_loss: 0.5941  time: 61s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4604  avg_val_loss: 0.5941  time: 61s\n","Epoch 3 - Score: 0.7129\n","INFO:__main__:Epoch 3 - Score: 0.7129\n","Epoch 3 - Save Best Score: 0.7129 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7129 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6289(0.5941) \n","f1 score : 0.351931330472103\n","recall score : 0.2679738562091503\n","precision score : 0.5125\n","thresh : 0.65\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 55s) Loss: 0.3129(0.3129) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4144(0.2905) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.1827(0.2833) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1840(0.2770) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4783(0.4783) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2770  avg_val_loss: 0.6481  time: 61s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2770  avg_val_loss: 0.6481  time: 61s\n","Epoch 4 - Score: 0.7149\n","INFO:__main__:Epoch 4 - Score: 0.7149\n","Epoch 4 - Save Best Score: 0.7149 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7149 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6792(0.6481) \n","f1 score : 0.35294117647058826\n","recall score : 0.27450980392156865\n","precision score : 0.49411764705882355\n","thresh : 0.71\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 6s) Loss: 0.1365(0.1365) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.1317(0.1906) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.1134(0.1921) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1091(0.1895) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4597(0.4597) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1895  avg_val_loss: 0.6714  time: 61s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1895  avg_val_loss: 0.6714  time: 61s\n","Epoch 5 - Score: 0.7068\n","INFO:__main__:Epoch 5 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6818(0.6714) \n","f1 score : 0.32921810699588483\n","recall score : 0.26143790849673204\n","precision score : 0.4444444444444444\n","thresh : 0.72\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.6908\n","INFO:__main__:Score: 0.6908\n","ACC BEST Score: 0.7149\n","INFO:__main__:ACC BEST Score: 0.7149\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.35294117647058826\n","recall score : 0.27450980392156865\n","precision score : 0.49411764705882355\n","thresh : 0.71\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 26s) Loss: 0.7464(0.7464) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.6585(0.6173) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.7344(0.6183) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.6503(0.6128) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6279(0.6279) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6128  avg_val_loss: 0.6596  time: 62s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6128  avg_val_loss: 0.6596  time: 62s\n","Epoch 1 - Score: 0.7129\n","INFO:__main__:Epoch 1 - Score: 0.7129\n","Epoch 1 - Save Best Score: 0.7129 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7129 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6606(0.6596) \n","f1 score : 0.47088607594936704\n","recall score : 0.6078431372549019\n","precision score : 0.384297520661157\n","thresh : 0.65\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 0s) Loss: 0.6823(0.6823) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5572(0.5764) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.6801(0.5638) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6362(0.5673) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4910(0.4910) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5673  avg_val_loss: 0.5881  time: 61s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5673  avg_val_loss: 0.5881  time: 61s\n","Epoch 2 - Score: 0.7088\n","INFO:__main__:Epoch 2 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5174(0.5881) \n","f1 score : 0.13953488372093023\n","recall score : 0.0784313725490196\n","precision score : 0.631578947368421\n","thresh : 0.54\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 59s) Loss: 0.6235(0.6235) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4581(0.5405) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.6614(0.5543) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4220(0.5430) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4071(0.4071) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5430  avg_val_loss: 0.5798  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5430  avg_val_loss: 0.5798  time: 62s\n","Epoch 3 - Score: 0.7108\n","INFO:__main__:Epoch 3 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4449(0.5798) \n","f1 score : 0.19672131147540983\n","recall score : 0.11764705882352941\n","precision score : 0.6\n","thresh : 0.55\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 10s) Loss: 0.4598(0.4598) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 33s) Loss: 0.5924(0.4593) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 37s (remain 0m 14s) Loss: 0.2470(0.4439) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4045(0.4357) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.3922(0.3922) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.4357  avg_val_loss: 0.5888  time: 61s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.4357  avg_val_loss: 0.5888  time: 61s\n","Epoch 4 - Score: 0.7088\n","INFO:__main__:Epoch 4 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4383(0.5888) \n","f1 score : 0.30973451327433627\n","recall score : 0.22875816993464052\n","precision score : 0.4794520547945205\n","thresh : 0.65\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 19s) Loss: 0.4308(0.4308) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 33s) Loss: 0.6549(0.3737) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.2375(0.3744) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3140(0.3723) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4168(0.4168) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.3723  avg_val_loss: 0.5903  time: 61s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.3723  avg_val_loss: 0.5903  time: 61s\n","Epoch 5 - Score: 0.7108\n","INFO:__main__:Epoch 5 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4725(0.5903) \n","f1 score : 0.35797665369649806\n","recall score : 0.3006535947712418\n","precision score : 0.4423076923076923\n","thresh : 0.69\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.5803\n","INFO:__main__:Score: 0.5803\n","ACC BEST Score: 0.7129\n","INFO:__main__:ACC BEST Score: 0.7129\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47088607594936704\n","recall score : 0.6078431372549019\n","precision score : 0.384297520661157\n","thresh : 0.65\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 17s) Loss: 0.6971(0.6971) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 19s (remain 0m 33s) Loss: 0.5412(0.6343) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.4991(0.6286) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5383(0.6205) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5592(0.5592) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6205  avg_val_loss: 0.6060  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6205  avg_val_loss: 0.6060  time: 61s\n","Epoch 1 - Score: 0.7068\n","INFO:__main__:Epoch 1 - Score: 0.7068\n","Epoch 1 - Save Best Score: 0.7068 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7068 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.3610(0.6060) \n","f1 score : 0.10975609756097561\n","recall score : 0.058823529411764705\n","precision score : 0.8181818181818182\n","thresh : 0.45\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 19s) Loss: 0.4072(0.4072) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5224(0.5784) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.6993(0.5695) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4808(0.5641) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5114(0.5114) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5641  avg_val_loss: 0.5776  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5641  avg_val_loss: 0.5776  time: 62s\n","Epoch 2 - Score: 0.7169\n","INFO:__main__:Epoch 2 - Score: 0.7169\n","Epoch 2 - Save Best Score: 0.7169 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7169 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.3804(0.5776) \n","f1 score : 0.18390804597701152\n","recall score : 0.10457516339869281\n","precision score : 0.7619047619047619\n","thresh : 0.48\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 31s) Loss: 0.5766(0.5766) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 35s) Loss: 0.2760(0.4620) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.6308(0.4594) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4783(0.4567) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5826(0.5826) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4567  avg_val_loss: 0.5916  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4567  avg_val_loss: 0.5916  time: 62s\n","Epoch 3 - Score: 0.7249\n","INFO:__main__:Epoch 3 - Score: 0.7249\n","Epoch 3 - Save Best Score: 0.7249 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7249 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4180(0.5916) \n","f1 score : 0.41843971631205673\n","recall score : 0.38562091503267976\n","precision score : 0.4573643410852713\n","thresh : 0.69\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 23s) Loss: 0.3346(0.3346) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 35s) Loss: 0.1860(0.3103) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.2346(0.3073) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2938(0.3056) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5911(0.5911) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3056  avg_val_loss: 0.6257  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3056  avg_val_loss: 0.6257  time: 62s\n","Epoch 4 - Score: 0.7209\n","INFO:__main__:Epoch 4 - Score: 0.7209\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.3715(0.6257) \n","f1 score : 0.39183673469387753\n","recall score : 0.3137254901960784\n","precision score : 0.5217391304347826\n","thresh : 0.75\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 15s) Loss: 0.2101(0.2101) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.1658(0.2179) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.2901(0.2130) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2356(0.2137) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6206(0.6206) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2137  avg_val_loss: 0.6462  time: 62s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.2137  avg_val_loss: 0.6462  time: 62s\n","Epoch 5 - Score: 0.7149\n","INFO:__main__:Epoch 5 - Score: 0.7149\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.3796(0.6462) \n","f1 score : 0.4153846153846154\n","recall score : 0.35294117647058826\n","precision score : 0.5046728971962616\n","thresh : 0.62\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.6707\n","INFO:__main__:Score: 0.6707\n","ACC BEST Score: 0.7249\n","INFO:__main__:ACC BEST Score: 0.7249\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.41843971631205673\n","recall score : 0.38562091503267976\n","precision score : 0.4573643410852713\n","thresh : 0.69\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 35s) Loss: 0.7633(0.7633) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 20s (remain 0m 35s) Loss: 0.4871(0.6568) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.6114(0.6296) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4387(0.6179) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6742(0.6742) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6179  avg_val_loss: 0.5951  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6179  avg_val_loss: 0.5951  time: 61s\n","Epoch 1 - Score: 0.7108\n","INFO:__main__:Epoch 1 - Score: 0.7108\n","Epoch 1 - Save Best Score: 0.7108 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7108 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6555(0.5951) \n","f1 score : 0.06329113924050632\n","recall score : 0.03289473684210526\n","precision score : 0.8333333333333334\n","thresh : 0.32\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 17s) Loss: 0.6180(0.6180) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.7758(0.5635) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.6854(0.5596) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.5643(0.5554) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6470(0.6470) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5554  avg_val_loss: 0.5761  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5554  avg_val_loss: 0.5761  time: 62s\n","Epoch 2 - Score: 0.7108\n","INFO:__main__:Epoch 2 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6401(0.5761) \n","f1 score : 0.09756097560975609\n","recall score : 0.05263157894736842\n","precision score : 0.6666666666666666\n","thresh : 0.48\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 15s) Loss: 0.3196(0.3196) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4282(0.4670) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.4682(0.4443) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3147(0.4347) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6275(0.6275) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4347  avg_val_loss: 0.6483  time: 61s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4347  avg_val_loss: 0.6483  time: 61s\n","Epoch 3 - Score: 0.7108\n","INFO:__main__:Epoch 3 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6409(0.6483) \n","f1 score : 0.3387096774193548\n","recall score : 0.27631578947368424\n","precision score : 0.4375\n","thresh : 0.78\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 16s) Loss: 0.2585(0.2585) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.2617(0.2748) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.1686(0.2510) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.1787(0.2494) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6250(0.6250) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2494  avg_val_loss: 0.6621  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2494  avg_val_loss: 0.6621  time: 62s\n","Epoch 4 - Score: 0.7209\n","INFO:__main__:Epoch 4 - Score: 0.7209\n","Epoch 4 - Save Best Score: 0.7209 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7209 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6835(0.6621) \n","f1 score : 0.4090909090909091\n","recall score : 0.35526315789473684\n","precision score : 0.48214285714285715\n","thresh : 0.78\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 3m 8s) Loss: 0.2231(0.2231) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 35s) Loss: 0.1225(0.1633) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.1356(0.1536) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.2939(0.1567) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6584(0.6584) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1567  avg_val_loss: 0.7189  time: 62s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1567  avg_val_loss: 0.7189  time: 62s\n","Epoch 5 - Score: 0.7169\n","INFO:__main__:Epoch 5 - Score: 0.7169\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7153(0.7189) \n","f1 score : 0.3878326996197719\n","recall score : 0.3355263157894737\n","precision score : 0.4594594594594595\n","thresh : 0.79\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.6867\n","INFO:__main__:Score: 0.6867\n","ACC BEST Score: 0.7209\n","INFO:__main__:ACC BEST Score: 0.7209\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4090909090909091\n","recall score : 0.35526315789473684\n","precision score : 0.48214285714285715\n","thresh : 0.78\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 29s) Loss: 0.5756(0.5756) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.6621(0.6260) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.5170(0.6151) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5089(0.6111) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5409(0.5409) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6111  avg_val_loss: 0.5894  time: 62s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6111  avg_val_loss: 0.5894  time: 62s\n","Epoch 1 - Score: 0.7062\n","INFO:__main__:Epoch 1 - Score: 0.7062\n","Epoch 1 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5367(0.5894) \n","f1 score : 0.08588957055214723\n","recall score : 0.046052631578947366\n","precision score : 0.6363636363636364\n","thresh : 0.79\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 6s) Loss: 0.6807(0.6807) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.6998(0.5706) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.4528(0.5642) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5670(0.5600) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.4941(0.4941) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5600  avg_val_loss: 0.5884  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5600  avg_val_loss: 0.5884  time: 62s\n","Epoch 2 - Score: 0.7143\n","INFO:__main__:Epoch 2 - Score: 0.7143\n","Epoch 2 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4471(0.5884) \n","f1 score : 0.1420118343195266\n","recall score : 0.07894736842105263\n","precision score : 0.7058823529411765\n","thresh : 0.45\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 13s) Loss: 0.5303(0.5303) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5898(0.4475) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.4006(0.4382) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6603(0.4448) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5171(0.5171) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4448  avg_val_loss: 0.6485  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4448  avg_val_loss: 0.6485  time: 62s\n","Epoch 3 - Score: 0.7123\n","INFO:__main__:Epoch 3 - Score: 0.7123\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4364(0.6485) \n","f1 score : 0.1411764705882353\n","recall score : 0.07894736842105263\n","precision score : 0.6666666666666666\n","thresh : 0.47\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 2s) Loss: 0.4312(0.4312) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4486(0.2861) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.2288(0.2757) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2002(0.2709) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.7106(0.7106) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2709  avg_val_loss: 0.6764  time: 61s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2709  avg_val_loss: 0.6764  time: 61s\n","Epoch 4 - Score: 0.7243\n","INFO:__main__:Epoch 4 - Score: 0.7243\n","Epoch 4 - Save Best Score: 0.7243 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7243 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4925(0.6764) \n","f1 score : 0.4098939929328622\n","recall score : 0.3815789473684211\n","precision score : 0.44274809160305345\n","thresh : 0.69\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 35s) Loss: 0.2124(0.2124) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.2706(0.1889) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.2209(0.1829) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1850(0.1821) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.8706(0.8706) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1821  avg_val_loss: 0.7440  time: 61s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1821  avg_val_loss: 0.7440  time: 61s\n","Epoch 5 - Score: 0.7203\n","INFO:__main__:Epoch 5 - Score: 0.7203\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4993(0.7440) \n","f1 score : 0.4357142857142857\n","recall score : 0.40131578947368424\n","precision score : 0.4765625\n","thresh : 0.73\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.6640\n","INFO:__main__:Score: 0.6640\n","ACC BEST Score: 0.7243\n","INFO:__main__:ACC BEST Score: 0.7243\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4098939929328622\n","recall score : 0.3815789473684211\n","precision score : 0.44274809160305345\n","thresh : 0.69\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 9s) Loss: 1.0564(1.0564) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5092(0.6357) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.5656(0.6205) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6053(0.6204) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.6309(0.6309) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6204  avg_val_loss: 0.6027  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6204  avg_val_loss: 0.6027  time: 61s\n","Epoch 1 - Score: 0.7082\n","INFO:__main__:Epoch 1 - Score: 0.7082\n","Epoch 1 - Save Best Score: 0.7082 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7082 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7308(0.6027) \n","f1 score : 0.08641975308641975\n","recall score : 0.046052631578947366\n","precision score : 0.7\n","thresh : 0.72\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 7s) Loss: 0.6583(0.6583) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 20s (remain 0m 35s) Loss: 0.6258(0.5768) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.5796(0.5635) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.3943(0.5609) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.6332(0.6332) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5609  avg_val_loss: 0.5816  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5609  avg_val_loss: 0.5816  time: 62s\n","Epoch 2 - Score: 0.7143\n","INFO:__main__:Epoch 2 - Score: 0.7143\n","Epoch 2 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6424(0.5816) \n","f1 score : 0.27999999999999997\n","recall score : 0.18421052631578946\n","precision score : 0.5833333333333334\n","thresh : 0.53\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 16s) Loss: 0.5682(0.5682) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5198(0.4593) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.4200(0.4622) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4461(0.4595) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.6311(0.6311) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4595  avg_val_loss: 0.5855  time: 61s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4595  avg_val_loss: 0.5855  time: 61s\n","Epoch 3 - Score: 0.7143\n","INFO:__main__:Epoch 3 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6528(0.5855) \n","f1 score : 0.37944664031620556\n","recall score : 0.3157894736842105\n","precision score : 0.4752475247524752\n","thresh : 0.71\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 39s) Loss: 0.4558(0.4558) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 35s) Loss: 0.3827(0.3105) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3145(0.2998) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2330(0.2944) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.7350(0.7350) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2944  avg_val_loss: 0.6595  time: 61s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2944  avg_val_loss: 0.6595  time: 61s\n","Epoch 4 - Score: 0.7082\n","INFO:__main__:Epoch 4 - Score: 0.7082\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.8293(0.6595) \n","f1 score : 0.3261802575107296\n","recall score : 0.25\n","precision score : 0.4691358024691358\n","thresh : 0.74\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 3s) Loss: 0.0968(0.0968) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.2485(0.2025) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3360(0.2005) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1940(0.1938) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.8027(0.8027) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1938  avg_val_loss: 0.6873  time: 61s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1938  avg_val_loss: 0.6873  time: 61s\n","Epoch 5 - Score: 0.7042\n","INFO:__main__:Epoch 5 - Score: 0.7042\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.8685(0.6873) \n","f1 score : 0.4045801526717557\n","recall score : 0.34868421052631576\n","precision score : 0.4818181818181818\n","thresh : 0.79\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.7103\n","INFO:__main__:Score: 0.7103\n","ACC BEST Score: 0.7143\n","INFO:__main__:ACC BEST Score: 0.7143\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.27999999999999997\n","recall score : 0.18421052631578946\n","precision score : 0.5833333333333334\n","thresh : 0.53\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 10s) Loss: 0.9143(0.9143) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.9693(0.6174) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.6464(0.6160) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5171(0.6139) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.5901(0.5901) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6139  avg_val_loss: 0.5970  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6139  avg_val_loss: 0.5970  time: 61s\n","Epoch 1 - Score: 0.7163\n","INFO:__main__:Epoch 1 - Score: 0.7163\n","Epoch 1 - Save Best Score: 0.7163 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7163 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5626(0.5970) \n","f1 score : 0.09937888198757765\n","recall score : 0.05263157894736842\n","precision score : 0.8888888888888888\n","thresh : 0.46\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 13s) Loss: 0.6006(0.6006) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.5845(0.5619) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.6559(0.5679) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5457(0.5745) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.5520(0.5520) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5745  avg_val_loss: 0.5834  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5745  avg_val_loss: 0.5834  time: 62s\n","Epoch 2 - Score: 0.7123\n","INFO:__main__:Epoch 2 - Score: 0.7123\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5688(0.5834) \n","f1 score : 0.13253012048192772\n","recall score : 0.07236842105263158\n","precision score : 0.7857142857142857\n","thresh : 0.48\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 13s) Loss: 0.5069(0.5069) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.3967(0.4918) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3204(0.4883) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6585(0.4862) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.4941(0.4941) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4862  avg_val_loss: 0.5933  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4862  avg_val_loss: 0.5933  time: 62s\n","Epoch 3 - Score: 0.7163\n","INFO:__main__:Epoch 3 - Score: 0.7163\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5941(0.5933) \n","f1 score : 0.37719298245614036\n","recall score : 0.28289473684210525\n","precision score : 0.5657894736842105\n","thresh : 0.51\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 14s) Loss: 0.3422(0.3422) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.3590(0.3209) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3741(0.3238) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1413(0.3212) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.4581(0.4581) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3212  avg_val_loss: 0.6178  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3212  avg_val_loss: 0.6178  time: 62s\n","Epoch 4 - Score: 0.7163\n","INFO:__main__:Epoch 4 - Score: 0.7163\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6914(0.6178) \n","f1 score : 0.40485829959514175\n","recall score : 0.32894736842105265\n","precision score : 0.5263157894736842\n","thresh : 0.55\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 11s) Loss: 0.2367(0.2367) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.1858(0.2471) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3536(0.2419) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.2930(0.2369) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 10s) Loss: 0.4640(0.4640) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2369  avg_val_loss: 0.6251  time: 62s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.2369  avg_val_loss: 0.6251  time: 62s\n","Epoch 5 - Score: 0.7143\n","INFO:__main__:Epoch 5 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6973(0.6251) \n","f1 score : 0.4033613445378151\n","recall score : 0.3157894736842105\n","precision score : 0.5581395348837209\n","thresh : 0.5\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.7082\n","INFO:__main__:Score: 0.7082\n","ACC BEST Score: 0.7163\n","INFO:__main__:ACC BEST Score: 0.7163\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.09937888198757765\n","recall score : 0.05263157894736842\n","precision score : 0.8888888888888888\n","thresh : 0.46\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 23s) Loss: 0.8001(0.8001) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 20s (remain 0m 35s) Loss: 0.4957(0.6406) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.5521(0.6258) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6000(0.6166) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6538(0.6538) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6166  avg_val_loss: 0.5853  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6166  avg_val_loss: 0.5853  time: 61s\n","Epoch 1 - Score: 0.7103\n","INFO:__main__:Epoch 1 - Score: 0.7103\n","Epoch 1 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7205(0.5853) \n","f1 score : 0.07594936708860758\n","recall score : 0.039473684210526314\n","precision score : 1.0\n","thresh : 0.39\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 20s) Loss: 0.4179(0.4179) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 35s) Loss: 0.4852(0.5637) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.5609(0.5728) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5726(0.5697) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6918(0.6918) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5697  avg_val_loss: 0.5775  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5697  avg_val_loss: 0.5775  time: 62s\n","Epoch 2 - Score: 0.7143\n","INFO:__main__:Epoch 2 - Score: 0.7143\n","Epoch 2 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7316(0.5775) \n","f1 score : 0.08750000000000001\n","recall score : 0.046052631578947366\n","precision score : 0.875\n","thresh : 0.38\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 45s) Loss: 0.4125(0.4125) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.6192(0.5184) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.4303(0.5055) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.4372(0.5018) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6937(0.6937) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.5018  avg_val_loss: 0.5738  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.5018  avg_val_loss: 0.5738  time: 62s\n","Epoch 3 - Score: 0.7143\n","INFO:__main__:Epoch 3 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6577(0.5738) \n","f1 score : 0.35833333333333334\n","recall score : 0.28289473684210525\n","precision score : 0.48863636363636365\n","thresh : 0.6\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 18s) Loss: 0.4038(0.4038) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.3048(0.3497) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3317(0.3489) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.3541(0.3511) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.7346(0.7346) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3511  avg_val_loss: 0.5915  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3511  avg_val_loss: 0.5915  time: 62s\n","Epoch 4 - Score: 0.7143\n","INFO:__main__:Epoch 4 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7348(0.5915) \n","f1 score : 0.2922374429223744\n","recall score : 0.21052631578947367\n","precision score : 0.47761194029850745\n","thresh : 0.58\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 52s) Loss: 0.3004(0.3004) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.3221(0.2646) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3002(0.2630) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.2868(0.2626) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.7571(0.7571) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2626  avg_val_loss: 0.5961  time: 62s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.2626  avg_val_loss: 0.5961  time: 62s\n","Epoch 5 - Score: 0.7183\n","INFO:__main__:Epoch 5 - Score: 0.7183\n","Epoch 5 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 5 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7303(0.5961) \n","f1 score : 0.39024390243902435\n","recall score : 0.3157894736842105\n","precision score : 0.5106382978723404\n","thresh : 0.43\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.6982\n","INFO:__main__:Score: 0.6982\n","ACC BEST Score: 0.7183\n","INFO:__main__:ACC BEST Score: 0.7183\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.39024390243902435\n","recall score : 0.3157894736842105\n","precision score : 0.5106382978723404\n","thresh : 0.43\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 27s) Loss: 0.6154(0.6154) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 20s (remain 0m 35s) Loss: 0.6232(0.6269) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.3284(0.6191) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6794(0.6160) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.5886(0.5886) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6160  avg_val_loss: 0.6308  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6160  avg_val_loss: 0.6308  time: 61s\n","Epoch 1 - Score: 0.7123\n","INFO:__main__:Epoch 1 - Score: 0.7123\n","Epoch 1 - Save Best Score: 0.7123 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7123 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.8340(0.6308) \n","f1 score : 0.08750000000000001\n","recall score : 0.046052631578947366\n","precision score : 0.875\n","thresh : 0.27\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 18s) Loss: 0.7336(0.7336) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4627(0.5747) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.4572(0.5729) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5376(0.5698) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6158(0.6158) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5698  avg_val_loss: 0.5965  time: 62s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5698  avg_val_loss: 0.5965  time: 62s\n","Epoch 2 - Score: 0.7163\n","INFO:__main__:Epoch 2 - Score: 0.7163\n","Epoch 2 - Save Best Score: 0.7163 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7163 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7031(0.5965) \n","f1 score : 0.09876543209876543\n","recall score : 0.05263157894736842\n","precision score : 0.8\n","thresh : 0.41\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 6s) Loss: 0.5827(0.5827) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4567(0.4701) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.4746(0.4669) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.6313(0.4662) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6134(0.6134) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4662  avg_val_loss: 0.5906  time: 61s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4662  avg_val_loss: 0.5906  time: 61s\n","Epoch 3 - Score: 0.7143\n","INFO:__main__:Epoch 3 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.6894(0.5906) \n","f1 score : 0.3559322033898305\n","recall score : 0.27631578947368424\n","precision score : 0.5\n","thresh : 0.68\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 22s) Loss: 0.2636(0.2636) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4367(0.3183) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.2126(0.3123) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.2359(0.3125) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.5934(0.5934) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.3125  avg_val_loss: 0.6341  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.3125  avg_val_loss: 0.6341  time: 62s\n","Epoch 4 - Score: 0.7143\n","INFO:__main__:Epoch 4 - Score: 0.7143\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7982(0.6341) \n","f1 score : 0.3318385650224215\n","recall score : 0.24342105263157895\n","precision score : 0.5211267605633803\n","thresh : 0.66\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 18s) Loss: 0.2363(0.2363) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.3374(0.2395) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.1502(0.2297) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.1866(0.2262) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 12s) Loss: 0.6129(0.6129) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.2262  avg_val_loss: 0.6386  time: 61s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.2262  avg_val_loss: 0.6386  time: 61s\n","Epoch 5 - Score: 0.7163\n","INFO:__main__:Epoch 5 - Score: 0.7163\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.7867(0.6386) \n","f1 score : 0.34567901234567905\n","recall score : 0.27631578947368424\n","precision score : 0.46153846153846156\n","thresh : 0.65\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.7062\n","INFO:__main__:Score: 0.7062\n","ACC BEST Score: 0.7163\n","INFO:__main__:ACC BEST Score: 0.7163\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.09876543209876543\n","recall score : 0.05263157894736842\n","precision score : 0.8\n","thresh : 0.41\n"]},{"output_type":"stream","name":"stderr","text":["BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","INFO:__main__:BartConfig {\n","  \"_name_or_path\": \"sshleifer/distilbart-cnn-12-6\",\n","  \"_num_labels\": 3,\n","  \"activation_dropout\": 0.0,\n","  \"activation_function\": \"gelu\",\n","  \"add_bias_logits\": false,\n","  \"add_final_layer_norm\": false,\n","  \"architectures\": [\n","    \"BartForConditionalGeneration\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"bos_token_id\": 0,\n","  \"classif_dropout\": 0.0,\n","  \"classifier_dropout\": 0.0,\n","  \"d_model\": 1024,\n","  \"decoder_attention_heads\": 16,\n","  \"decoder_ffn_dim\": 4096,\n","  \"decoder_layerdrop\": 0.0,\n","  \"decoder_layers\": 6,\n","  \"decoder_start_token_id\": 2,\n","  \"dropout\": 0.1,\n","  \"early_stopping\": true,\n","  \"encoder_attention_heads\": 16,\n","  \"encoder_ffn_dim\": 4096,\n","  \"encoder_layerdrop\": 0.0,\n","  \"encoder_layers\": 12,\n","  \"eos_token_id\": 2,\n","  \"extra_pos_embeddings\": 2,\n","  \"force_bos_token_to_be_generated\": true,\n","  \"forced_bos_token_id\": 0,\n","  \"forced_eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\"\n","  },\n","  \"init_std\": 0.02,\n","  \"is_encoder_decoder\": true,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2\n","  },\n","  \"length_penalty\": 2.0,\n","  \"max_length\": 142,\n","  \"max_position_embeddings\": 1024,\n","  \"min_length\": 56,\n","  \"model_type\": \"bart\",\n","  \"no_repeat_ngram_size\": 3,\n","  \"normalize_before\": false,\n","  \"normalize_embedding\": true,\n","  \"num_beams\": 4,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"output_past\": true,\n","  \"pad_token_id\": 1,\n","  \"prefix\": \" \",\n","  \"replacing_rate\": 0,\n","  \"scale_embedding\": false,\n","  \"static_position_embeddings\": false,\n","  \"student_decoder_layers\": null,\n","  \"student_encoder_layers\": null,\n","  \"task_specific_params\": {\n","    \"summarization\": {\n","      \"early_stopping\": true,\n","      \"length_penalty\": 2.0,\n","      \"max_length\": 142,\n","      \"min_length\": 56,\n","      \"no_repeat_ngram_size\": 3,\n","      \"num_beams\": 4\n","    }\n","  },\n","  \"transformers_version\": \"4.28.1\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50264\n","}\n","\n","Some weights of the model checkpoint at sshleifer/distilbart-cnn-12-6 were not used when initializing BartModel: ['final_logits_bias']\n","- This IS expected if you are initializing BartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 30s) Loss: 0.7092(0.7092) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 18s (remain 0m 33s) Loss: 0.6360(0.6303) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 38s (remain 0m 14s) Loss: 0.6117(0.6199) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 53s (remain 0m 0s) Loss: 0.5456(0.6098) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5709(0.5709) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6098  avg_val_loss: 0.5856  time: 61s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6098  avg_val_loss: 0.5856  time: 61s\n","Epoch 1 - Score: 0.7062\n","INFO:__main__:Epoch 1 - Score: 0.7062\n","Epoch 1 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5413(0.5856) \n","f1 score : 0.07547169811320754\n","recall score : 0.039473684210526314\n","precision score : 0.8571428571428571\n","thresh : 0.46\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 2m 11s) Loss: 0.4254(0.4254) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 19s (remain 0m 33s) Loss: 0.5039(0.5675) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.6322(0.5654) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.5023(0.5587) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.5607(0.5607) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5587  avg_val_loss: 0.5800  time: 61s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5587  avg_val_loss: 0.5800  time: 61s\n","Epoch 2 - Score: 0.7062\n","INFO:__main__:Epoch 2 - Score: 0.7062\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.5171(0.5800) \n","f1 score : 0.2210526315789474\n","recall score : 0.13815789473684212\n","precision score : 0.5526315789473685\n","thresh : 0.6\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 8s) Loss: 0.5257(0.5257) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.4600(0.4377) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.6036(0.4367) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.4514(0.4296) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.6302(0.6302) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.4296  avg_val_loss: 0.6109  time: 62s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.4296  avg_val_loss: 0.6109  time: 62s\n","Epoch 3 - Score: 0.7062\n","INFO:__main__:Epoch 3 - Score: 0.7062\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4655(0.6109) \n","f1 score : 0.354978354978355\n","recall score : 0.26973684210526316\n","precision score : 0.5189873417721519\n","thresh : 0.71\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 2m 23s) Loss: 0.2168(0.2168) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.1570(0.2414) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 38s (remain 0m 15s) Loss: 0.1690(0.2399) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.1546(0.2372) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 0.8851(0.8851) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2372  avg_val_loss: 0.7156  time: 62s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2372  avg_val_loss: 0.7156  time: 62s\n","Epoch 4 - Score: 0.7002\n","INFO:__main__:Epoch 4 - Score: 0.7002\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.4161(0.7156) \n","f1 score : 0.45051194539249145\n","recall score : 0.4342105263157895\n","precision score : 0.46808510638297873\n","thresh : 0.77\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 2m 21s) Loss: 0.1010(0.1010) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 19s (remain 0m 34s) Loss: 0.2486(0.1482) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 39s (remain 0m 15s) Loss: 0.1112(0.1491) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 54s (remain 0m 0s) Loss: 0.1189(0.1501) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 11s) Loss: 1.0002(1.0002) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.1501  avg_val_loss: 0.7786  time: 62s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.1501  avg_val_loss: 0.7786  time: 62s\n","Epoch 5 - Score: 0.7062\n","INFO:__main__:Epoch 5 - Score: 0.7062\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 7s (remain 0m 0s) Loss: 0.3932(0.7786) \n","f1 score : 0.4172661870503597\n","recall score : 0.3815789473684211\n","precision score : 0.4603174603174603\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 9 result ==========\n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xLy2EqucW--T"},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SBcToO10Ok_c"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPmLFivNJy2zLwckfd2z0nk"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}