{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19562,"status":"ok","timestamp":1683226429638,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"sMVmfQcW79nK","outputId":"8cf4699c-a4a5-4652-c994-b05bb27c0ee5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22198,"status":"ok","timestamp":1683226451832,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"PMsVsVYs8Jib","outputId":"802de3b3-5a89-4874-8cc6-990a6110bcf2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting aiohttp\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.4.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n","Collecting dill<0.3.7,>=0.3.0\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.14.1)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, multidict, frozenlist, dill, async-timeout, yarl, responses, multiprocess, aiosignal, aiohttp, datasets\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 datasets-2.12.0 dill-0.3.6 frozenlist-1.3.3 multidict-6.0.4 multiprocess-0.70.14 responses-0.18.0 xxhash-3.2.0 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1683226452226,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"qonwoL_F8Oe_","outputId":"d38482a7-5637-4493-b267-902d9c2d99e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Thu May  4 18:54:11 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   30C    P0    43W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"y2tBjTH68Qnb","executionInfo":{"status":"ok","timestamp":1683226460072,"user_tz":-540,"elapsed":7847,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"JyQ97ca88dRA","executionInfo":{"status":"ok","timestamp":1683226462239,"user_tz":-540,"elapsed":2172,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","DIR = \"/content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","CUSTOM_MODEL_DIR = os.path.join(OUTPUT_DIR,'clrp_deberta_v3_base_epoch10')\n","OUTPUT_EXP_DIR = DIR + '/output/EXP063/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"VCF2-czO8Svr","executionInfo":{"status":"ok","timestamp":1683226462240,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model_name=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    model = CUSTOM_MODEL_DIR\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=5\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","    num_reinit_layers = 1\n","    is_reinit_layer = False\n","    fgm = False\n","    awp_start=1\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"7QkA50jQ80_3","executionInfo":{"status":"ok","timestamp":1683226462240,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return accuracy_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_acc_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = accuracy_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    print(f\"thresh : {best_thresh}\")\n","    return accuracy_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=CFG.seed)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"wRnSUEJR9A9y","executionInfo":{"status":"ok","timestamp":1683226462240,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","    \n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","        \n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","    \n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","            \n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","    \n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","        \n","        if hasattr(embeddings_path, attr_name): \n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":450},"executionInfo":{"elapsed":859,"status":"ok","timestamp":1683226463094,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"GUnukiIG9FM5","outputId":"c8bf36f1-b56a-4c17-a1e9-dfd207b95e65"},"outputs":[{"output_type":"stream","name":"stdout","text":["(4974, 7)\n"]},{"output_type":"display_data","data":{"text/plain":["   index    id                                              title  year  \\\n","0    721   722  Global Optimality Conditions for Deep Neural N...  2018   \n","1    144   145  Multi-Task Learning by Deep Collaboration and ...  2018   \n","2   4542  4543  On the Need for Topology-Aware Generative Mode...  2020   \n","\n","                                            abstract  \\\n","0  We study the error landscape of deep linear an...   \n","1  Convolutional neural networks (CNN) have becom...   \n","2  ML algorithms or models, especially deep neura...   \n","\n","                                            keywords  y  \n","0  deep linear neural networks, global optimality...  1  \n","1  multi-task learning, soft parameter sharing, f...  0  \n","2  Manifold-based Defense, Robust Learning, Adver...  1  "],"text/html":["\n","  <div id=\"df-47ba4cae-9b3a-42d5-995e-3e04db60e61f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>721</td>\n","      <td>722</td>\n","      <td>Global Optimality Conditions for Deep Neural N...</td>\n","      <td>2018</td>\n","      <td>We study the error landscape of deep linear an...</td>\n","      <td>deep linear neural networks, global optimality...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>144</td>\n","      <td>145</td>\n","      <td>Multi-Task Learning by Deep Collaboration and ...</td>\n","      <td>2018</td>\n","      <td>Convolutional neural networks (CNN) have becom...</td>\n","      <td>multi-task learning, soft parameter sharing, f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4542</td>\n","      <td>4543</td>\n","      <td>On the Need for Topology-Aware Generative Mode...</td>\n","      <td>2020</td>\n","      <td>ML algorithms or models, especially deep neura...</td>\n","      <td>Manifold-based Defense, Robust Learning, Adver...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47ba4cae-9b3a-42d5-995e-3e04db60e61f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-47ba4cae-9b3a-42d5-995e-3e04db60e61f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-47ba4cae-9b3a-42d5-995e-3e04db60e61f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 5)\n"]},{"output_type":"display_data","data":{"text/plain":["   id                                              title  year  \\\n","0   1  StyleAlign: Analysis and Applications of Align...  2022   \n","1   2  Embedding a random graph via GNN: mean-field i...  2021   \n","2   3  BBRefinement: an universal scheme to improve p...  2021   \n","\n","                                            abstract  \\\n","0  In this paper, we perform an in-depth study of...   \n","1  We develop a theory for embedding a random gra...   \n","2  We present a conceptually simple yet powerful ...   \n","\n","                                            keywords  \n","0  StyleGAN, transfer learning, fine tuning, mode...  \n","1  Graph neural network, graph embedding, multi-r...  \n","2  object detection, deep neural networks, refine...  "],"text/html":["\n","  <div id=\"df-14a7f09e-f4c7-4512-83f3-f6cd3bb13946\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>year</th>\n","      <th>abstract</th>\n","      <th>keywords</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>StyleAlign: Analysis and Applications of Align...</td>\n","      <td>2022</td>\n","      <td>In this paper, we perform an in-depth study of...</td>\n","      <td>StyleGAN, transfer learning, fine tuning, mode...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Embedding a random graph via GNN: mean-field i...</td>\n","      <td>2021</td>\n","      <td>We develop a theory for embedding a random gra...</td>\n","      <td>Graph neural network, graph embedding, multi-r...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>BBRefinement: an universal scheme to improve p...</td>\n","      <td>2021</td>\n","      <td>We present a conceptually simple yet powerful ...</td>\n","      <td>object detection, deep neural networks, refine...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-14a7f09e-f4c7-4512-83f3-f6cd3bb13946')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-14a7f09e-f4c7-4512-83f3-f6cd3bb13946 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-14a7f09e-f4c7-4512-83f3-f6cd3bb13946');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(6393, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["   id  y\n","0   1  0\n","1   2  0\n","2   3  0"],"text/html":["\n","  <div id=\"df-7393d31b-1692-4d6a-8f71-3f140889a9a5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7393d31b-1692-4d6a-8f71-3f140889a9a5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7393d31b-1692-4d6a-8f71-3f140889a9a5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7393d31b-1692-4d6a-8f71-3f140889a9a5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train_data.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test_data.csv\"))\n","sample_sub = pd.read_csv(os.path.join(INPUT_DIR,\"submission.csv\"))\n","\n","train = train.sample(frac=1, random_state=CFG.seed).reset_index()\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(sample_sub.shape)\n","display(sample_sub.head(3))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"S2LAKUbZ9L92","executionInfo":{"status":"ok","timestamp":1683226463095,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["train[\"texts\"] = train[\"title\"] + \"[SEP]\" + train[\"abstract\"] "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"9MRHQQ6K9Zot","executionInfo":{"status":"ok","timestamp":1683226463095,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train.y)):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","    \n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"kTf6lgW19iep","executionInfo":{"status":"ok","timestamp":1683226465099,"user_tz":-540,"elapsed":2008,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3879,"status":"ok","timestamp":1683226468974,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"wt2P1uC_9oRd","outputId":"6a95bdcc-1f22-4c7f-e219-318b48e81c20"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 4974/4974 [00:03<00:00, 1337.83it/s]\n","max_len: 522\n","INFO:__main__:max_len: 522\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 3 # cls + sep + sep\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","source":["class AWP:\n","    def __init__(self, model, optimizer, *, adv_param='weight',\n","                 adv_lr=0.001, adv_eps=0.001):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.backup = {}\n","\n","    def perturb(self, inputs, y, criterion):\n","        \"\"\"\n","        Perturb model parameters for AWP gradient\n","        Call before loss and loss.backward()\n","        \"\"\"\n","        self._save()  # save model parameters\n","        self._attack_step()  # perturb weights\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                grad = self.optimizer.state[param]['exp_avg']\n","                norm_grad = torch.norm(grad)\n","                norm_data = torch.norm(param.detach())\n","\n","                if norm_grad != 0 and not torch.isnan(norm_grad):\n","                    # Set lower and upper limit in change\n","                    limit_eps = self.adv_eps * param.detach().abs()\n","                    param_min = param.data - limit_eps\n","                    param_max = param.data + limit_eps\n","\n","                    # Perturb along gradient\n","                    # w += (adv_lr * |w| / |grad|) * grad\n","                    param.data.add_(grad, alpha=(self.adv_lr * (norm_data + e) / (norm_grad + e)))\n","\n","                    # Apply the limit to the change\n","                    param.data.clamp_(param_min, param_max)\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.clone().detach()\n","                else:\n","                    self.backup[name].copy_(param.data)\n","\n","    def restore(self):\n","        \"\"\"\n","        Restore model parameter to correct position; AWP do not perturbe weights, it perturb gradients\n","        Call after loss.backward(), before optimizer.step()\n","        \"\"\"\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data.copy_(self.backup[name])"],"metadata":{"id":"GGPvvwObFq6u","executionInfo":{"status":"ok","timestamp":1683226468974,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","execution_count":15,"metadata":{"id":"rmsbpfsc92bq","executionInfo":{"status":"ok","timestamp":1683226468974,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df['y'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"]},{"cell_type":"code","source":["def reinit_layers(model):\n","\n","    #for layer in model.model.encoder.layer[-CFG.num_reinit_layers:]:\n","    for layer in model.encoder.layer[-CFG.num_reinit_layers:]:    #Custome model内(backbone)\n","\n","            for module in layer.modules():\n","\n","                if isinstance(module,nn.Linear):\n","                    module.weight.data.normal_(mean=0.0,std=model.config.initializer_range)\n","                    if module.bias is not None:\n","                            module.bias.data.zero_()\n","                elif isinstance(module, nn.Embedding):\n","                        module.weight.data.normal_(mean=0.0, std=model.config.initializer_range)\n","                        if module.padding_idx is not None:\n","                            module.weight.data[module.padding_idx].zero_()\n","                elif isinstance(module, nn.LayerNorm):\n","                        module.bias.data.zero_()\n","                        module.weight.data.fill_(1.0)\n","                        \n","    return model"],"metadata":{"id":"7_1lWWHZ83or","executionInfo":{"status":"ok","timestamp":1683226468975,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","execution_count":17,"metadata":{"id":"DbE2YLRd9-uk","executionInfo":{"status":"ok","timestamp":1683226468975,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","        \n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","    \n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if CFG.is_reinit_layer:\n","            self.model = reinit_layers(self.model)\n","            print(f'Reinitializing Last {CFG.num_reinit_layers} Layers.')\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MaxPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self._init_weights(self.fc)\n","\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        #output = self.sig(output)\n","        return output"]},{"cell_type":"code","source":["def calculate_loss(inputs, labels, model, criterion, is_valid=True, device=\"cpu\"):    \n","    y_preds = model(inputs)\n","    loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","    return (loss, y_preds) if is_valid else loss"],"metadata":{"id":"ON_p7meJH_tB","executionInfo":{"status":"ok","timestamp":1683226468976,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Evhi1yCQ-Xjb","executionInfo":{"status":"ok","timestamp":1683226468976,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, awp):\n","    model.zero_grad()\n","    model.train()\n","    awp_start = CFG.awp_start\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        if epoch >= awp_start:\n","            awp.perturb(inputs, labels, criterion)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            loss = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=False, device=device)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        #loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        if scaler is not None:\n","            scaler.unscale_(optimizer)\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        awp.restore()\n","        if CFG.fgm:\n","          fgm.attack() \n","          adversarial_loss = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=False, device=device)\n","          scaler.scale(adversarial_loss).backward()\n","          fgm.restore()\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  #'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          #grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            loss, y_preds = calculate_loss(inputs=inputs, labels=labels, model=model, criterion=criterion, is_valid=True, device=device)\n","        #loss = criterion(y_preds.sigmoid().squeeze(), labels.squeeze())\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"pR91ZhBL_pW4","executionInfo":{"status":"ok","timestamp":1683226468976,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['y'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr=5e-6, decoder_lr=1e-4, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \n","                    \"LayerNorm.weight\"]\n","        group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n","        group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n","        group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n","        group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n","        optimizer_parameters = [\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': weight_decay},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': weight_decay, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': weight_decay, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': weight_decay, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': encoder_lr/2.6},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': encoder_lr},\n","        {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': encoder_lr*2.6},\n","        {'params': [p for n, p in model.named_parameters() if \"model\" not in n], 'lr':decoder_lr, \"momentum\" : 0.99},\n","    ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    print('Enable AWP')\n","    awp = AWP(model, optimizer, adv_lr=0.001, adv_eps=0.001)\n","    #print('Enable FGM')\n","    #fgm = FGM(model=model, eps=0.1)\n","    \n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, awp)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score_05 = get_score(valid_labels, predictions)\n","        score = get_acc_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model_name.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZY5kSe1_1Fl","outputId":"3c8a22b0-8206-49ab-d021-7010c8e02dfd","executionInfo":{"status":"ok","timestamp":1683228354270,"user_tz":-540,"elapsed":1885301,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 4s (remain 18m 55s) Loss: 0.6411(0.6411) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 15s (remain 0m 27s) Loss: 0.8209(0.6225) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 26s (remain 0m 10s) Loss: 0.6975(0.6167) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 35s (remain 0m 0s) Loss: 0.5455(0.6141) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6022(0.6022) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6141  avg_val_loss: 0.5944  time: 39s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6141  avg_val_loss: 0.5944  time: 39s\n","Epoch 1 - Score: 0.7169\n","INFO:__main__:Epoch 1 - Score: 0.7169\n","Epoch 1 - Save Best Score: 0.7169 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7169 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6459(0.5944) \n","f1 score : 0.11042944785276074\n","recall score : 0.058823529411764705\n","precision score : 0.9\n","thresh : 0.35\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.9142(0.9142) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.7304(0.5388) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.3838(0.5242) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.7500(0.5300) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.5803(0.5803) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5300  avg_val_loss: 0.5881  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5300  avg_val_loss: 0.5881  time: 36s\n","Epoch 2 - Score: 0.7129\n","INFO:__main__:Epoch 2 - Score: 0.7129\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7111(0.5881) \n","f1 score : 0.14285714285714285\n","recall score : 0.0784313725490196\n","precision score : 0.8\n","thresh : 0.41\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 24s) Loss: 0.4055(0.4055) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2781(0.3499) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.3046(0.3399) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.3601(0.3235) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5640(0.5640) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3235  avg_val_loss: 0.6273  time: 35s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3235  avg_val_loss: 0.6273  time: 35s\n","Epoch 3 - Score: 0.7189\n","INFO:__main__:Epoch 3 - Score: 0.7189\n","Epoch 3 - Save Best Score: 0.7189 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7189 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6589(0.6273) \n","f1 score : 0.2512562814070352\n","recall score : 0.16339869281045752\n","precision score : 0.5434782608695652\n","thresh : 0.64\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.1139(0.1139) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0530(0.0950) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0894(0.0894) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0620(0.0853) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5788(0.5788) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0853  avg_val_loss: 0.6454  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0853  avg_val_loss: 0.6454  time: 36s\n","Epoch 4 - Score: 0.7108\n","INFO:__main__:Epoch 4 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6648(0.6454) \n","f1 score : 0.2938388625592417\n","recall score : 0.20261437908496732\n","precision score : 0.5344827586206896\n","thresh : 0.42\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 27s) Loss: 0.0418(0.0418) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0451(0.0465) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0433(0.0458) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0519(0.0453) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5981(0.5981) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0453  avg_val_loss: 0.6580  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0453  avg_val_loss: 0.6580  time: 36s\n","Epoch 5 - Score: 0.7108\n","INFO:__main__:Epoch 5 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6723(0.6580) \n","f1 score : 0.2788461538461538\n","recall score : 0.1895424836601307\n","precision score : 0.5272727272727272\n","thresh : 0.4\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n","Score: 0.7008\n","INFO:__main__:Score: 0.7008\n","ACC BEST Score: 0.7189\n","INFO:__main__:ACC BEST Score: 0.7189\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.2512562814070352\n","recall score : 0.16339869281045752\n","precision score : 0.5434782608695652\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.6861(0.6861) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.7377(0.6204) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.3722(0.6193) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.7071(0.6162) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4778(0.4778) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6162  avg_val_loss: 0.5893  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6162  avg_val_loss: 0.5893  time: 35s\n","Epoch 1 - Score: 0.7189\n","INFO:__main__:Epoch 1 - Score: 0.7189\n","Epoch 1 - Save Best Score: 0.7189 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7189 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5123(0.5893) \n","f1 score : 0.13333333333333333\n","recall score : 0.0718954248366013\n","precision score : 0.9166666666666666\n","thresh : 0.39\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.6478(0.6478) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.6989(0.5518) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.4828(0.5341) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3944(0.5316) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4080(0.4080) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5316  avg_val_loss: 0.5893  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5316  avg_val_loss: 0.5893  time: 36s\n","Epoch 2 - Score: 0.7189\n","INFO:__main__:Epoch 2 - Score: 0.7189\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4819(0.5893) \n","f1 score : 0.12195121951219513\n","recall score : 0.06535947712418301\n","precision score : 0.9090909090909091\n","thresh : 0.41\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.4401(0.4401) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.3043(0.3565) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.3675(0.3344) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.2077(0.3112) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3850(0.3850) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3112  avg_val_loss: 0.6679  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3112  avg_val_loss: 0.6679  time: 36s\n","Epoch 3 - Score: 0.7068\n","INFO:__main__:Epoch 3 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5571(0.6679) \n","f1 score : 0.1935483870967742\n","recall score : 0.11764705882352941\n","precision score : 0.5454545454545454\n","thresh : 0.67\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.0358(0.0358) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.0598(0.0859) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0552(0.0790) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0489(0.0765) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3957(0.3957) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0765  avg_val_loss: 0.6479  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0765  avg_val_loss: 0.6479  time: 36s\n","Epoch 4 - Score: 0.7068\n","INFO:__main__:Epoch 4 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5657(0.6479) \n","f1 score : 0.26540284360189575\n","recall score : 0.1830065359477124\n","precision score : 0.4827586206896552\n","thresh : 0.64\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 37s) Loss: 0.0614(0.0614) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0506(0.0466) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.0480(0.0460) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0336(0.0456) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.3954(0.3954) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0456  avg_val_loss: 0.6575  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0456  avg_val_loss: 0.6575  time: 36s\n","Epoch 5 - Score: 0.7028\n","INFO:__main__:Epoch 5 - Score: 0.7028\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5535(0.6575) \n","f1 score : 0.2608695652173913\n","recall score : 0.17647058823529413\n","precision score : 0.5\n","thresh : 0.63\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n","Score: 0.7129\n","INFO:__main__:Score: 0.7129\n","ACC BEST Score: 0.7189\n","INFO:__main__:ACC BEST Score: 0.7189\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.13333333333333333\n","recall score : 0.0718954248366013\n","precision score : 0.9166666666666666\n","thresh : 0.39\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 2m 0s) Loss: 0.9049(0.9049) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.7167(0.6171) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.6193(0.6142) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.5931(0.6081) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6049(0.6049) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6081  avg_val_loss: 0.5919  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6081  avg_val_loss: 0.5919  time: 35s\n","Epoch 1 - Score: 0.7088\n","INFO:__main__:Epoch 1 - Score: 0.7088\n","Epoch 1 - Save Best Score: 0.7088 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7088 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4150(0.5919) \n","f1 score : 0.1581920903954802\n","recall score : 0.0915032679738562\n","precision score : 0.5833333333333334\n","thresh : 0.58\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 46s) Loss: 0.5300(0.5300) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.5357(0.5445) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.6088(0.5270) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4630(0.5191) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6401(0.6401) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5191  avg_val_loss: 0.6070  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5191  avg_val_loss: 0.6070  time: 36s\n","Epoch 2 - Score: 0.7108\n","INFO:__main__:Epoch 2 - Score: 0.7108\n","Epoch 2 - Save Best Score: 0.7108 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7108 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4004(0.6070) \n","f1 score : 0.3769230769230769\n","recall score : 0.3202614379084967\n","precision score : 0.45794392523364486\n","thresh : 0.58\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.3237(0.3237) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.3188(0.3253) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.3005(0.3095) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1669(0.2959) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6466(0.6466) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2959  avg_val_loss: 0.6435  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2959  avg_val_loss: 0.6435  time: 36s\n","Epoch 3 - Score: 0.7068\n","INFO:__main__:Epoch 3 - Score: 0.7068\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3022(0.6435) \n","f1 score : 0.3018867924528302\n","recall score : 0.20915032679738563\n","precision score : 0.5423728813559322\n","thresh : 0.73\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.0831(0.0831) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0476(0.0794) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.0608(0.0730) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0645(0.0699) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7015(0.7015) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0699  avg_val_loss: 0.6746  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0699  avg_val_loss: 0.6746  time: 36s\n","Epoch 4 - Score: 0.7088\n","INFO:__main__:Epoch 4 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3243(0.6746) \n","f1 score : 0.3177570093457944\n","recall score : 0.2222222222222222\n","precision score : 0.5573770491803278\n","thresh : 0.52\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 35s) Loss: 0.0467(0.0467) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0377(0.0418) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.0429(0.0417) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.0395(0.0418) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7093(0.7093) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0418  avg_val_loss: 0.6909  time: 35s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0418  avg_val_loss: 0.6909  time: 35s\n","Epoch 5 - Score: 0.7108\n","INFO:__main__:Epoch 5 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3283(0.6909) \n","f1 score : 0.29411764705882354\n","recall score : 0.19607843137254902\n","precision score : 0.5882352941176471\n","thresh : 0.5\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n","Score: 0.6747\n","INFO:__main__:Score: 0.6747\n","ACC BEST Score: 0.7108\n","INFO:__main__:ACC BEST Score: 0.7108\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.3769230769230769\n","recall score : 0.3202614379084967\n","precision score : 0.45794392523364486\n","thresh : 0.58\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.7654(0.7654) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.6659(0.6245) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.6275(0.6156) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.7163(0.6100) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.6759(0.6759) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6100  avg_val_loss: 0.5862  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6100  avg_val_loss: 0.5862  time: 35s\n","Epoch 1 - Score: 0.7108\n","INFO:__main__:Epoch 1 - Score: 0.7108\n","Epoch 1 - Save Best Score: 0.7108 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7108 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5928(0.5862) \n","f1 score : 0.13714285714285715\n","recall score : 0.07894736842105263\n","precision score : 0.5217391304347826\n","thresh : 0.46\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.5716(0.5716) LR: 0.00001808  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.4826(0.5243) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.4130(0.5179) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.6041(0.5206) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.6624(0.6624) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5206  avg_val_loss: 0.5832  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5206  avg_val_loss: 0.5832  time: 36s\n","Epoch 2 - Score: 0.7088\n","INFO:__main__:Epoch 2 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6251(0.5832) \n","f1 score : 0.22340425531914895\n","recall score : 0.13815789473684212\n","precision score : 0.5833333333333334\n","thresh : 0.51\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.3396(0.3396) LR: 0.00001309  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.3129(0.3446) LR: 0.00001090  \n","Epoch: [3][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.1942(0.3181) LR: 0.00000866  \n","Epoch: [3][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.3217(0.3012) LR: 0.00000695  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.7378(0.7378) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3012  avg_val_loss: 0.6545  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3012  avg_val_loss: 0.6545  time: 36s\n","Epoch 3 - Score: 0.7008\n","INFO:__main__:Epoch 3 - Score: 0.7008\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7107(0.6545) \n","f1 score : 0.5222222222222223\n","recall score : 0.618421052631579\n","precision score : 0.4519230769230769\n","thresh : 0.78\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 44s) Loss: 0.2215(0.2215) LR: 0.00000693  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0875(0.0969) LR: 0.00000488  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0522(0.0861) LR: 0.00000310  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0719(0.0821) LR: 0.00000194  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.8720(0.8720) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0821  avg_val_loss: 0.6541  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0821  avg_val_loss: 0.6541  time: 36s\n","Epoch 4 - Score: 0.7088\n","INFO:__main__:Epoch 4 - Score: 0.7088\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5819(0.6541) \n","f1 score : 0.2692307692307692\n","recall score : 0.18421052631578946\n","precision score : 0.5\n","thresh : 0.65\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 38s) Loss: 0.0518(0.0518) LR: 0.00000193  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0340(0.0481) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0354(0.0488) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0503(0.0489) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.9019(0.9019) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0489  avg_val_loss: 0.6694  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0489  avg_val_loss: 0.6694  time: 36s\n","Epoch 5 - Score: 0.7108\n","INFO:__main__:Epoch 5 - Score: 0.7108\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5838(0.6694) \n","f1 score : 0.25742574257425743\n","recall score : 0.17105263157894737\n","precision score : 0.52\n","thresh : 0.64\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n","Score: 0.6968\n","INFO:__main__:Score: 0.6968\n","ACC BEST Score: 0.7108\n","INFO:__main__:ACC BEST Score: 0.7108\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.13714285714285715\n","recall score : 0.07894736842105263\n","precision score : 0.5217391304347826\n","thresh : 0.46\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 52s) Loss: 0.9318(0.9318) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.5529(0.6326) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.5599(0.6122) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.5801(0.6121) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5112(0.5112) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6121  avg_val_loss: 0.5897  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6121  avg_val_loss: 0.5897  time: 35s\n","Epoch 1 - Score: 0.7042\n","INFO:__main__:Epoch 1 - Score: 0.7042\n","Epoch 1 - Save Best Score: 0.7042 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7042 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5532(0.5897) \n","f1 score : 0.08588957055214723\n","recall score : 0.046052631578947366\n","precision score : 0.6363636363636364\n","thresh : 0.41\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.6799(0.6799) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.6506(0.5296) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.4455(0.5374) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4707(0.5290) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.4880(0.4880) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5290  avg_val_loss: 0.5867  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5290  avg_val_loss: 0.5867  time: 36s\n","Epoch 2 - Score: 0.7062\n","INFO:__main__:Epoch 2 - Score: 0.7062\n","Epoch 2 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5223(0.5867) \n","f1 score : 0.1694915254237288\n","recall score : 0.09868421052631579\n","precision score : 0.6\n","thresh : 0.45\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.5320(0.5320) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.3403(0.3517) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2264(0.3304) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2630(0.3113) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6113(0.6113) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.3113  avg_val_loss: 0.6354  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.3113  avg_val_loss: 0.6354  time: 36s\n","Epoch 3 - Score: 0.7022\n","INFO:__main__:Epoch 3 - Score: 0.7022\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6425(0.6354) \n","f1 score : 0.4234527687296417\n","recall score : 0.4276315789473684\n","precision score : 0.41935483870967744\n","thresh : 0.73\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.2138(0.2138) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0641(0.1005) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.0684(0.0863) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.0551(0.0797) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5474(0.5474) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0797  avg_val_loss: 0.6744  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0797  avg_val_loss: 0.6744  time: 36s\n","Epoch 4 - Score: 0.7103\n","INFO:__main__:Epoch 4 - Score: 0.7103\n","Epoch 4 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5299(0.6744) \n","f1 score : 0.28436018957345965\n","recall score : 0.19736842105263158\n","precision score : 0.5084745762711864\n","thresh : 0.79\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.0287(0.0287) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0274(0.0406) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0483(0.0407) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0582(0.0401) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5508(0.5508) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0401  avg_val_loss: 0.6717  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0401  avg_val_loss: 0.6717  time: 36s\n","Epoch 5 - Score: 0.7062\n","INFO:__main__:Epoch 5 - Score: 0.7062\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5194(0.6717) \n","f1 score : 0.29493087557603687\n","recall score : 0.21052631578947367\n","precision score : 0.49230769230769234\n","thresh : 0.55\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n","Score: 0.6962\n","INFO:__main__:Score: 0.6962\n","ACC BEST Score: 0.7103\n","INFO:__main__:ACC BEST Score: 0.7103\n","========== fold: 5 training ==========\n","INFO:__main__:========== fold: 5 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.28436018957345965\n","recall score : 0.19736842105263158\n","precision score : 0.5084745762711864\n","thresh : 0.79\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.6972(0.6972) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.6158(0.6271) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.4331(0.6122) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.5497(0.6079) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6043(0.6043) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6079  avg_val_loss: 0.5924  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6079  avg_val_loss: 0.5924  time: 35s\n","Epoch 1 - Score: 0.7062\n","INFO:__main__:Epoch 1 - Score: 0.7062\n","Epoch 1 - Save Best Score: 0.7062 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7062 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7081(0.5924) \n","f1 score : 0.08695652173913043\n","recall score : 0.046052631578947366\n","precision score : 0.7777777777777778\n","thresh : 0.55\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.6411(0.6411) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.4366(0.5296) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.5496(0.5251) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.6753(0.5155) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6638(0.6638) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5155  avg_val_loss: 0.6201  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5155  avg_val_loss: 0.6201  time: 36s\n","Epoch 2 - Score: 0.7082\n","INFO:__main__:Epoch 2 - Score: 0.7082\n","Epoch 2 - Save Best Score: 0.7082 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7082 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7755(0.6201) \n","f1 score : 0.08641975308641975\n","recall score : 0.046052631578947366\n","precision score : 0.7\n","thresh : 0.3\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 50s) Loss: 0.3490(0.3490) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2890(0.3241) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1981(0.2967) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1476(0.2792) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7322(0.7322) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2792  avg_val_loss: 0.6022  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2792  avg_val_loss: 0.6022  time: 36s\n","Epoch 3 - Score: 0.7183\n","INFO:__main__:Epoch 3 - Score: 0.7183\n","Epoch 3 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6824(0.6022) \n","f1 score : 0.3225806451612903\n","recall score : 0.23026315789473684\n","precision score : 0.5384615384615384\n","thresh : 0.57\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 50s) Loss: 0.0988(0.0988) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0763(0.0777) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0691(0.0735) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0673(0.0704) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8499(0.8499) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0704  avg_val_loss: 0.6659  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0704  avg_val_loss: 0.6659  time: 36s\n","Epoch 4 - Score: 0.7183\n","INFO:__main__:Epoch 4 - Score: 0.7183\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8564(0.6659) \n","f1 score : 0.24598930481283424\n","recall score : 0.1513157894736842\n","precision score : 0.6571428571428571\n","thresh : 0.51\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.0338(0.0338) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0393(0.0425) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.0428(0.0426) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.0326(0.0428) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.8292(0.8292) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0428  avg_val_loss: 0.6470  time: 35s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0428  avg_val_loss: 0.6470  time: 35s\n","Epoch 5 - Score: 0.7183\n","INFO:__main__:Epoch 5 - Score: 0.7183\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7986(0.6470) \n","f1 score : 0.27860696517412936\n","recall score : 0.18421052631578946\n","precision score : 0.5714285714285714\n","thresh : 0.55\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 5 result ==========\n","INFO:__main__:========== fold: 5 result ==========\n","Score: 0.7042\n","INFO:__main__:Score: 0.7042\n","ACC BEST Score: 0.7183\n","INFO:__main__:ACC BEST Score: 0.7183\n","========== fold: 6 training ==========\n","INFO:__main__:========== fold: 6 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.3225806451612903\n","recall score : 0.23026315789473684\n","precision score : 0.5384615384615384\n","thresh : 0.57\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 1.0733(1.0733) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.4964(0.6401) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.6636(0.6272) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.5415(0.6154) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6248(0.6248) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6154  avg_val_loss: 0.5834  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6154  avg_val_loss: 0.5834  time: 35s\n","Epoch 1 - Score: 0.7103\n","INFO:__main__:Epoch 1 - Score: 0.7103\n","Epoch 1 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5161(0.5834) \n","f1 score : 0.12048192771084337\n","recall score : 0.06578947368421052\n","precision score : 0.7142857142857143\n","thresh : 0.57\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.6027(0.6027) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.5797(0.5375) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.5825(0.5236) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4160(0.5216) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6245(0.6245) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5216  avg_val_loss: 0.5944  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5216  avg_val_loss: 0.5944  time: 36s\n","Epoch 2 - Score: 0.7123\n","INFO:__main__:Epoch 2 - Score: 0.7123\n","Epoch 2 - Save Best Score: 0.7123 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7123 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5122(0.5944) \n","f1 score : 0.1798941798941799\n","recall score : 0.1118421052631579\n","precision score : 0.4594594594594595\n","thresh : 0.61\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 50s) Loss: 0.3916(0.3916) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.2468(0.3402) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1634(0.3114) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2876(0.2887) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5492(0.5492) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2887  avg_val_loss: 0.6242  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2887  avg_val_loss: 0.6242  time: 36s\n","Epoch 3 - Score: 0.7243\n","INFO:__main__:Epoch 3 - Score: 0.7243\n","Epoch 3 - Save Best Score: 0.7243 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7243 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6765(0.6242) \n","f1 score : 0.43150684931506855\n","recall score : 0.4144736842105263\n","precision score : 0.45\n","thresh : 0.66\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.1209(0.1209) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.0657(0.0736) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0491(0.0696) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1217(0.0672) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6097(0.6097) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0672  avg_val_loss: 0.6712  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0672  avg_val_loss: 0.6712  time: 36s\n","Epoch 4 - Score: 0.7243\n","INFO:__main__:Epoch 4 - Score: 0.7243\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6044(0.6712) \n","f1 score : 0.32075471698113206\n","recall score : 0.2236842105263158\n","precision score : 0.5666666666666667\n","thresh : 0.59\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.0398(0.0398) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.0342(0.0414) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0377(0.0415) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0404(0.0412) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6102(0.6102) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0412  avg_val_loss: 0.6748  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0412  avg_val_loss: 0.6748  time: 36s\n","Epoch 5 - Score: 0.7243\n","INFO:__main__:Epoch 5 - Score: 0.7243\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6082(0.6748) \n","f1 score : 0.3222748815165877\n","recall score : 0.2236842105263158\n","precision score : 0.576271186440678\n","thresh : 0.55\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 6 result ==========\n","INFO:__main__:========== fold: 6 result ==========\n","Score: 0.6660\n","INFO:__main__:Score: 0.6660\n","ACC BEST Score: 0.7243\n","INFO:__main__:ACC BEST Score: 0.7243\n","========== fold: 7 training ==========\n","INFO:__main__:========== fold: 7 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.43150684931506855\n","recall score : 0.4144736842105263\n","precision score : 0.45\n","thresh : 0.66\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 48s) Loss: 0.6410(0.6410) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.5983(0.6265) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 22s (remain 0m 8s) Loss: 0.5417(0.6138) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.5719(0.6084) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6781(0.6781) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6084  avg_val_loss: 0.6013  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6084  avg_val_loss: 0.6013  time: 36s\n","Epoch 1 - Score: 0.7163\n","INFO:__main__:Epoch 1 - Score: 0.7163\n","Epoch 1 - Save Best Score: 0.7163 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7163 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6888(0.6013) \n","f1 score : 0.23469387755102042\n","recall score : 0.1513157894736842\n","precision score : 0.5227272727272727\n","thresh : 0.55\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 36s) Loss: 0.5314(0.5314) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.4979(0.5099) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.3874(0.5074) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4626(0.5083) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6700(0.6700) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5083  avg_val_loss: 0.5724  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5083  avg_val_loss: 0.5724  time: 36s\n","Epoch 2 - Score: 0.7163\n","INFO:__main__:Epoch 2 - Score: 0.7163\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7180(0.5724) \n","f1 score : 0.28712871287128716\n","recall score : 0.19078947368421054\n","precision score : 0.58\n","thresh : 0.52\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.2908(0.2908) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.3343(0.2947) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1772(0.2780) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.2242(0.2631) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 7s) Loss: 0.6754(0.6754) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2631  avg_val_loss: 0.5905  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2631  avg_val_loss: 0.5905  time: 36s\n","Epoch 3 - Score: 0.7183\n","INFO:__main__:Epoch 3 - Score: 0.7183\n","Epoch 3 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6949(0.5905) \n","f1 score : 0.4427480916030534\n","recall score : 0.3815789473684211\n","precision score : 0.5272727272727272\n","thresh : 0.74\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 45s) Loss: 0.0836(0.0836) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.0912(0.0736) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0805(0.0672) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0419(0.0647) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7419(0.7419) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0647  avg_val_loss: 0.6122  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0647  avg_val_loss: 0.6122  time: 36s\n","Epoch 4 - Score: 0.7223\n","INFO:__main__:Epoch 4 - Score: 0.7223\n","Epoch 4 - Save Best Score: 0.7223 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7223 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8298(0.6122) \n","f1 score : 0.3272727272727273\n","recall score : 0.23684210526315788\n","precision score : 0.5294117647058824\n","thresh : 0.79\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 50s) Loss: 0.0402(0.0402) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0478(0.0408) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0508(0.0410) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0418(0.0404) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7763(0.7763) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0404  avg_val_loss: 0.6312  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0404  avg_val_loss: 0.6312  time: 36s\n","Epoch 5 - Score: 0.7223\n","INFO:__main__:Epoch 5 - Score: 0.7223\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.8897(0.6312) \n","f1 score : 0.3106796116504854\n","recall score : 0.21052631578947367\n","precision score : 0.5925925925925926\n","thresh : 0.73\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 7 result ==========\n","INFO:__main__:========== fold: 7 result ==========\n","Score: 0.7022\n","INFO:__main__:Score: 0.7022\n","ACC BEST Score: 0.7223\n","INFO:__main__:ACC BEST Score: 0.7223\n","========== fold: 8 training ==========\n","INFO:__main__:========== fold: 8 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.3272727272727273\n","recall score : 0.23684210526315788\n","precision score : 0.5294117647058824\n","thresh : 0.79\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 56s) Loss: 0.6759(0.6759) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.6022(0.6251) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.3891(0.6075) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 31s (remain 0m 0s) Loss: 0.4067(0.6041) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.5924(0.5924) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6041  avg_val_loss: 0.5876  time: 35s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6041  avg_val_loss: 0.5876  time: 35s\n","Epoch 1 - Score: 0.7183\n","INFO:__main__:Epoch 1 - Score: 0.7183\n","Epoch 1 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.7298(0.5876) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n","thresh : 0.35\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 40s) Loss: 0.6441(0.6441) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.5079(0.5205) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.6616(0.5174) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4820(0.5214) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6418(0.6418) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5214  avg_val_loss: 0.5810  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5214  avg_val_loss: 0.5810  time: 36s\n","Epoch 2 - Score: 0.7324\n","INFO:__main__:Epoch 2 - Score: 0.7324\n","Epoch 2 - Save Best Score: 0.7324 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7324 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6426(0.5810) \n","f1 score : 0.358974358974359\n","recall score : 0.27631578947368424\n","precision score : 0.5121951219512195\n","thresh : 0.59\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 1m 34s) Loss: 0.3461(0.3461) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.3005(0.3263) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.2392(0.3052) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1710(0.2879) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6667(0.6667) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2879  avg_val_loss: 0.5986  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2879  avg_val_loss: 0.5986  time: 36s\n","Epoch 3 - Score: 0.7183\n","INFO:__main__:Epoch 3 - Score: 0.7183\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6056(0.5986) \n","f1 score : 0.3317972350230415\n","recall score : 0.23684210526315788\n","precision score : 0.5538461538461539\n","thresh : 0.59\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 41s) Loss: 0.0832(0.0832) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0454(0.0784) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.1492(0.0727) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1163(0.0707) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7184(0.7184) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0707  avg_val_loss: 0.6124  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0707  avg_val_loss: 0.6124  time: 36s\n","Epoch 4 - Score: 0.7284\n","INFO:__main__:Epoch 4 - Score: 0.7284\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6262(0.6124) \n","f1 score : 0.34259259259259256\n","recall score : 0.24342105263157895\n","precision score : 0.578125\n","thresh : 0.56\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 42s) Loss: 0.0448(0.0448) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 21s) Loss: 0.0372(0.0457) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.0462(0.0443) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0424(0.0445) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7338(0.7338) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0445  avg_val_loss: 0.6285  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0445  avg_val_loss: 0.6285  time: 36s\n","Epoch 5 - Score: 0.7284\n","INFO:__main__:Epoch 5 - Score: 0.7284\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.6801(0.6285) \n","f1 score : 0.3054187192118227\n","recall score : 0.20394736842105263\n","precision score : 0.6078431372549019\n","thresh : 0.56\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 8 result ==========\n","INFO:__main__:========== fold: 8 result ==========\n","Score: 0.6982\n","INFO:__main__:Score: 0.6982\n","ACC BEST Score: 0.7324\n","INFO:__main__:ACC BEST Score: 0.7324\n","========== fold: 9 training ==========\n","INFO:__main__:========== fold: 9 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"/content/drive/MyDrive/Competitions/probspace/\\u7814\\u7a76\\u8ad6\\u6587\\u306e\\u56fd\\u969b\\u5b66\\u4f1a\\u63a1\\u629e\\u4e88\\u6e2c/output/clrp_deberta_v3_base_epoch10\",\n","  \"architectures\": [\n","    \"DebertaV2ForMaskedLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"torch_dtype\": \"float32\",\n","  \"transformers_version\": \"4.28.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.358974358974359\n","recall score : 0.27631578947368424\n","precision score : 0.5121951219512195\n","thresh : 0.59\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at /content/drive/MyDrive/Competitions/probspace/研究論文の国際学会採択予測/output/clrp_deberta_v3_base_epoch10 were not used when initializing DebertaV2Model: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Enable AWP\n","Epoch: [1][0/279] Elapsed 0m 0s (remain 1m 51s) Loss: 0.6582(0.6582) LR: 0.00002000  \n","Epoch: [1][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.7878(0.6290) LR: 0.00001974  \n","Epoch: [1][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.5966(0.6109) LR: 0.00001900  \n","Epoch: [1][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3299(0.6080) LR: 0.00001810  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6053(0.6053) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6080  avg_val_loss: 0.5941  time: 36s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.6080  avg_val_loss: 0.5941  time: 36s\n","Epoch 1 - Score: 0.7103\n","INFO:__main__:Epoch 1 - Score: 0.7103\n","Epoch 1 - Save Best Score: 0.7103 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.7103 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.5136(0.5941) \n","f1 score : 0.03870967741935484\n","recall score : 0.019736842105263157\n","precision score : 1.0\n","thresh : 0.39\n","Epoch: [2][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.4758(0.4758) LR: 0.00001809  \n","Epoch: [2][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.4387(0.5284) LR: 0.00001657  \n","Epoch: [2][200/279] Elapsed 0m 23s (remain 0m 8s) Loss: 0.5480(0.5214) LR: 0.00001473  \n","Epoch: [2][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.5271(0.5200) LR: 0.00001312  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.6126(0.6126) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.5200  avg_val_loss: 0.5889  time: 36s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.5200  avg_val_loss: 0.5889  time: 36s\n","Epoch 2 - Score: 0.7143\n","INFO:__main__:Epoch 2 - Score: 0.7143\n","Epoch 2 - Save Best Score: 0.7143 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.7143 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.4478(0.5889) \n","f1 score : 0.13095238095238093\n","recall score : 0.07236842105263158\n","precision score : 0.6875\n","thresh : 0.47\n","Epoch: [3][0/279] Elapsed 0m 0s (remain 2m 0s) Loss: 0.3323(0.3323) LR: 0.00001310  \n","Epoch: [3][100/279] Elapsed 0m 12s (remain 0m 21s) Loss: 0.3099(0.3522) LR: 0.00001091  \n","Epoch: [3][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.3122(0.3119) LR: 0.00000867  \n","Epoch: [3][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.1370(0.2948) LR: 0.00000696  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7233(0.7233) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2948  avg_val_loss: 0.6298  time: 36s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2948  avg_val_loss: 0.6298  time: 36s\n","Epoch 3 - Score: 0.7123\n","INFO:__main__:Epoch 3 - Score: 0.7123\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3753(0.6298) \n","f1 score : 0.2613065326633166\n","recall score : 0.17105263157894737\n","precision score : 0.5531914893617021\n","thresh : 0.62\n","Epoch: [4][0/279] Elapsed 0m 0s (remain 1m 43s) Loss: 0.1682(0.1682) LR: 0.00000694  \n","Epoch: [4][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0498(0.0868) LR: 0.00000490  \n","Epoch: [4][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0605(0.0795) LR: 0.00000311  \n","Epoch: [4][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0653(0.0758) LR: 0.00000195  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7018(0.7018) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0758  avg_val_loss: 0.6206  time: 36s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0758  avg_val_loss: 0.6206  time: 36s\n","Epoch 4 - Score: 0.7183\n","INFO:__main__:Epoch 4 - Score: 0.7183\n","Epoch 4 - Save Best Score: 0.7183 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.7183 Model\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3533(0.6206) \n","f1 score : 0.351931330472103\n","recall score : 0.26973684210526316\n","precision score : 0.5061728395061729\n","thresh : 0.71\n","Epoch: [5][0/279] Elapsed 0m 0s (remain 1m 39s) Loss: 0.0504(0.0504) LR: 0.00000194  \n","Epoch: [5][100/279] Elapsed 0m 11s (remain 0m 20s) Loss: 0.0382(0.0443) LR: 0.00000082  \n","Epoch: [5][200/279] Elapsed 0m 23s (remain 0m 9s) Loss: 0.0351(0.0443) LR: 0.00000017  \n","Epoch: [5][278/279] Elapsed 0m 32s (remain 0m 0s) Loss: 0.0506(0.0447) LR: 0.00000000  \n","EVAL: [0/16] Elapsed 0m 0s (remain 0m 6s) Loss: 0.7145(0.7145) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5 - avg_train_loss: 0.0447  avg_val_loss: 0.6403  time: 36s\n","INFO:__main__:Epoch 5 - avg_train_loss: 0.0447  avg_val_loss: 0.6403  time: 36s\n","Epoch 5 - Score: 0.7163\n","INFO:__main__:Epoch 5 - Score: 0.7163\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [15/16] Elapsed 0m 3s (remain 0m 0s) Loss: 0.3380(0.6403) \n","f1 score : 0.29767441860465116\n","recall score : 0.21052631578947367\n","precision score : 0.5079365079365079\n","thresh : 0.61\n"]},{"output_type":"stream","name":"stderr","text":["========== fold: 9 result ==========\n","INFO:__main__:========== fold: 9 result ==========\n","Score: 0.6962\n","INFO:__main__:Score: 0.6962\n","ACC BEST Score: 0.7183\n","INFO:__main__:ACC BEST Score: 0.7183\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n","Score: 0.6948\n","INFO:__main__:Score: 0.6948\n","ACC BEST Score: 0.7091\n","INFO:__main__:ACC BEST Score: 0.7091\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.351931330472103\n","recall score : 0.26973684210526316\n","precision score : 0.5061728395061729\n","thresh : 0.71\n","f1 score : 0.31187669990933814\n","recall score : 0.22586999343401182\n","precision score : 0.5036603221083455\n","thresh : 0.64\n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['y'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        acc_score = get_acc_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'ACC BEST Score: {acc_score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"xLy2EqucW--T","executionInfo":{"status":"ok","timestamp":1683228354271,"user_tz":-540,"elapsed":20,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["from google.colab import runtime\n","runtime.unassign()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"SBcToO10Ok_c","executionInfo":{"status":"ok","timestamp":1683228354271,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyMRdmE//SLADqFCK6diFvQn"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}